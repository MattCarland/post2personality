{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz1xaYf4cEjg"
      },
      "source": [
        "Double Check That everything works,\n",
        "make sure to upload all necessary files. Download preprocessed set and use it. DONE\n",
        "\n",
        "Update pkl files to be put in the model folder. DONE\n",
        "\n",
        "Test out the three model types on a big preprocessed Dataset. See if there are any better results.\n",
        "\n",
        "Tell team that BERT is stupid long and still doesn't work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7HZ1m4t7MWt5"
      },
      "outputs": [],
      "source": [
        "###### GLOBAL ###########\n",
        "\n",
        "INSTALL_NEEDED = False\n",
        "\n",
        "## Load CSV Datasets\n",
        "MAKE_DATA = False\n",
        "ROWS = 85000 # LIMIT = 85000\n",
        "DF1, DF2, DF3 = False, True, False\n",
        "ALL_ROWS = False\n",
        "\n",
        "# Build PreProccessed Datasets\n",
        "## PICK ONE FOR PREPROCESSING ##\n",
        "# If all False, will attempt to load our preproccessed data\n",
        "PREPROCESS = False # Use our Preproccessing\n",
        "BERT_PREPROCESS = False # Use BERT Preproceccessing\n",
        "BERT_LOAD = False # Load Preproccessed BERT Data\n",
        "\n",
        "# Set model types for session ('SGD', 'XGB', 'ADA')\n",
        "MODEL_TYPE = 'SGD'\n",
        "\n",
        "# Build Models\n",
        "NEW_MODELS = False\n",
        "\n",
        "# Search for Parameters\n",
        "PARAMETER_SEARCH = False\n",
        "\n",
        "# Train Models\n",
        "TRAIN = False\n",
        "\n",
        "# Predict Models\n",
        "PREDICT_TEST = True\n",
        "\n",
        "###### GLOBAL ###########"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46kuz5a8FLnq",
        "outputId": "9a79d74d-bc46-4fd6-f291-38cf8e477b99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (4.29.2)\n",
            "Requirement already satisfied: filelock in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from transformers) (2023.5.5)\n",
            "Requirement already satisfied: requests in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from transformers) (2.30.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GZHOFp9D-Lj",
        "outputId": "f7dc9a6d-f041-4559-b59b-e0b79f965ae3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.0.1)\n",
            "Requirement already satisfied: matplotlib in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: ipdb in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.13.13)\n",
            "Requirement already satisfied: seaborn in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.12.2)\n",
            "Collecting scipy==1.10.0 (from -r requirements.txt (line 5))\n",
            "  Using cached scipy-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "Collecting scikit-learn==1.2.1 (from -r requirements.txt (line 6))\n",
            "  Using cached scikit_learn-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "Requirement already satisfied: nltk in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (3.8.1)\n",
            "Requirement already satisfied: textblob in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.17.1)\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.0rc1 Requires-Python >=3.7,<3.10; 1.7.0rc2 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement string (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for string\u001b[0m\u001b[31m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-c9_nz0Yi0Jz"
      },
      "outputs": [],
      "source": [
        "\n",
        "if INSTALL_NEEDED == True:  \n",
        "  import nltk\n",
        "  nltk.download('punkt')\n",
        "  nltk.download('stopwords')\n",
        "  nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mq9Xvxoh_-vw",
        "outputId": "d4afbd27-56f1-4bc8-d6fe-842b71f491ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset contains 7811 rows\n",
            "\n",
            "Data already loaded\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "from data.data import Data as data_csv\n",
        "from scripts.Preprocessing_full import *\n",
        "from model.model import *\n",
        "\n",
        "\n",
        "if MAKE_DATA == True:\n",
        "  data_raw = data_csv().get_all_data()\n",
        "\n",
        "  data_list = []\n",
        "\n",
        "  # 8670 ROWS INPUT #\n",
        "  if DF1:\n",
        "    df1 = data_raw['twitter_MBTI']\n",
        "    df1 = df1[['label', 'text']]\n",
        "    df1.rename(columns={'label': 'type'}, inplace=True)\n",
        "    if ALL_ROWS == False:\n",
        "      df1 = df1.sample(n = ROWS, ignore_index = True)\n",
        "    data_list.append(df1)\n",
        "\n",
        "\n",
        "  # 106062 ROWS INPUT #\n",
        "  if DF2:\n",
        "    df2 = data_raw['MBTI 500']\n",
        "    df2 = df2[['type', 'posts']]\n",
        "    df2.rename(columns={'posts': 'text'}, inplace=True)\n",
        "    if ALL_ROWS == False:\n",
        "      df2 = df2.sample(n = ROWS, ignore_index = True)\n",
        "    data_list.append(df2)\n",
        "\n",
        "\n",
        "  # 7811 ROWS INPUT #\n",
        "  if DF3:\n",
        "    df3 = data_raw['mbti_1']\n",
        "    df3.rename(columns={'posts': 'text'}, inplace=True)\n",
        "    if ALL_ROWS == False:\n",
        "      df3 = df3.sample(n = ROWS, ignore_index = True)\n",
        "    data_list.append(df2)\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "\n",
        "\n",
        "  ## Combined all data for PP if desired\n",
        "  data_combined = pd.concat(data_list, ignore_index=True)\n",
        "  print(f\"data_combined ready with shape: {data_combined.shape}\")\n",
        "\n",
        "else:\n",
        "  print(\"Data already loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--zajHjRCPc0",
        "outputId": "ba5b209e-ff25-4fc6-b7e4-08dc36a79147"
      },
      "outputs": [],
      "source": [
        "# from scripts.Preprocessing_full import training_preprocessing, training_oversampling, training_balancing, training_vectorize\n",
        "# # from scripts.BERT_preprocessing import training_preprocessing as bert_training_preprocessing\n",
        "\n",
        "\n",
        "# if PREPROCESS:\n",
        "#   df_pp = training_preprocessing(data_combined)\n",
        "#   df_pp_os = training_oversampling(df_pp)\n",
        "#   df_pp_os_bal = training_balancing(df_pp_os)\n",
        "#   df_list = training_vectorize(df_pp_os_bal)\n",
        "\n",
        "#   df_list[0].dropna(inplace = True)\n",
        "#   df_list[1].dropna(inplace = True)\n",
        "#   df_list[2].dropna(inplace = True)\n",
        "#   df_list[3].dropna(inplace = True)\n",
        "\n",
        "#   with open(f'data/prepro/dflist_pp_{ROWS}.pkl', 'wb') as file:\n",
        "#     pickle.dump(df_list, file)\n",
        "  \n",
        "#   print(f\"df_list_pp_{ROWS} has been saved\")\n",
        "\n",
        "# elif BERT_PREPROCESS:\n",
        "# #   df_list = bert_training_preprocessing(data_combined)\n",
        "\n",
        "#   df_list[0].dropna(inplace = True)\n",
        "#   df_list[1].dropna(inplace = True)\n",
        "#   df_list[2].dropna(inplace = True)\n",
        "#   df_list[3].dropna(inplace = True)\n",
        "\n",
        "#   with open(f'data/prepro/dflist_pp_BERT_{ROWS}.pkl', 'wb') as file:\n",
        "#     pickle.dump(df_list, file)\n",
        "  \n",
        "#   print(f\"df_list_pp_BERT_{ROWS} has been saved\")\n",
        "\n",
        "# elif BERT_LOAD:\n",
        "#   with open(f'data/prepro/dflist_pp_BERT_{ROWS}.pkl', 'rb') as file:\n",
        "#     df_list = pickle.load(file)\n",
        "#   print(f\"data/prepro/dflist_pp_BERT_{ROWS} has been loaded\")\n",
        "  \n",
        "# else:\n",
        "#   with open(f'data/prepro/dflist_pp_{ROWS}.pkl', 'rb') as file:\n",
        "#     df_list = pickle.load(file)\n",
        "#   print(f\"df_list_pp_{ROWS} has been loaded as df_list\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSjxhLpgJQsc"
      },
      "source": [
        "<!--  -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8_z6_NvOCR8K"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmodel_list is NEW\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m   model_list \u001b[39m=\u001b[39m load_models_pkl()\n\u001b[1;32m      8\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmodel_list is OLD\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/code/MattCarland/post2personality/model/model.py:135\u001b[0m, in \u001b[0;36mload_models_pkl\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mwhile\u001b[39;00m i \u001b[39m<\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[1;32m    134\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodel/model\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m--> 135\u001b[0m         model \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(file)\n\u001b[1;32m    136\u001b[0m     model_list\u001b[39m.\u001b[39mappend(model)\n\u001b[1;32m    137\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel list loaded:\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages/sklearn/base.py:314\u001b[0m, in \u001b[0;36mBaseEstimator.__setstate__\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m         \u001b[39mreturn\u001b[39;00m state\n\u001b[0;32m--> 314\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__setstate__\u001b[39m(\u001b[39mself\u001b[39m, state):\n\u001b[1;32m    315\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39msklearn.\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    316\u001b[0m         pickle_version \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39m_sklearn_version\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpre-0.18\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "if NEW_MODELS:\n",
        "  model_list = initialize_models(new_models = True,\n",
        "                               params = None,\n",
        "                               model_type = MODEL_TYPE)\n",
        "  print(\"model_list is NEW\")\n",
        "else:\n",
        "  model_list = load_models_pkl()\n",
        "  print(\"model_list is OLD\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_LKOyI9CT_5"
      },
      "outputs": [],
      "source": [
        "if PARAMETER_SEARCH:\n",
        "  param_list = grid_search_all_models(df_list, \n",
        "                          model_type=MODEL_TYPE, \n",
        "                          rows_for_search=1000)\n",
        "  with open(f'model/param_list_{MODEL_TYPE}.pkl', 'wb') as file:\n",
        "    pickle.dump(param_list, file)\n",
        "  \n",
        "  model_list = initialize_models(params = param_list,\n",
        "                               model_type=MODEL_TYPE)\n",
        "  print(\"model_list is optimized on new params\")\n",
        "  \n",
        "else:\n",
        "  with open(f'model/param_list_{MODEL_TYPE}.pkl', 'rb') as file:\n",
        "    param_list = pickle.load(file)\n",
        "\n",
        "  model_list = initialize_models(params = param_list,\n",
        "                               model_type=MODEL_TYPE) \n",
        "  \n",
        "  print(\"model_list is optimized on old params\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Z-yfDLeCajV"
      },
      "outputs": [],
      "source": [
        "if TRAIN:\n",
        "  history = train_model(df_list, model_list)\n",
        "else:\n",
        "  print(\"Not Training\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIn2fmOYCg8s"
      },
      "outputs": [],
      "source": [
        "from scripts.Preprocessing_full import prediction_preprocessing, prediction_vectorize\n",
        "# from scripts.BERT_preprocessing import prediction_preprocessing as bert_prediction_preprocessing\n",
        "\n",
        "if not MAKE_DATA:\n",
        "  data_raw = data_csv().get_all_data()\n",
        "  df2 = data_raw['MBTI 500']\n",
        "  df2 = df2[['type', 'posts']]\n",
        "  df2.rename(columns={'posts': 'text'}, inplace=True)\n",
        "\n",
        "if PREDICT_TEST:\n",
        "  j = 0\n",
        "  for i in range(101):\n",
        "    df = df2.sample(n = 10, ignore_index = True)\n",
        "    estimation = df['type'].iloc[:1].tolist()[0]\n",
        "    df_pred = df.iloc[:1].drop(columns =['type'])\n",
        "\n",
        "    df_pred_pp = prediction_preprocessing(df_pred)\n",
        "    df_pred_list = prediction_vectorize(df_pred_pp)\n",
        "    pred = predict_model(texts = df_pred_list, verbose = False)\n",
        "    # print(f\"Prediction = {pred['type_prediction']} {pred['type_score']}\")\n",
        "    # print(f\"Actual = {estimation}\")\n",
        "    if pred['type_prediction'] == estimation:\n",
        "      j += 1\n",
        "  print(f\"{j} fully correct MBTI types out of {i}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfVFzbNNmo4j"
      },
      "source": [
        "# DF Comparison (n=7000)\n",
        "### DF1 ------------------------------------------\n",
        "F1-score: 52.669999999999995%\n",
        "MBTI Type: EI\n",
        "\n",
        "F1-score: 53.102000000000004%\n",
        "MBTI Type: NS\n",
        "\n",
        "F1-score: 49.124%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 57.786% \n",
        "MBTI Type: PJ\n",
        "\n",
        "### DF2 ------------------------------------------\n",
        "F1-score: 60.718%\n",
        "MBTI Type: EI\n",
        " \n",
        "F1-score: 60.75000000000001%\n",
        "MBTI Type: NS \n",
        "\n",
        "F1-score: 78.408%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 54.04600000000001%\n",
        "MBTI Type: PJ\n",
        "\n",
        "\n",
        "### DF 3 -------------------------------------\n",
        "\n",
        "\n",
        "F1-score: 58.536%\n",
        "MBTI Type: IE\n",
        "\n",
        "F1-score: 58.318999999999996%\n",
        "MBTI Type: NS\n",
        "\n",
        "F1-score: 66.681%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 57.265%\n",
        "MBTI Type: JP\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI2m3eud5cQ4"
      },
      "source": [
        "# Model Comparison (n=80000)\n",
        "### SGD ------------------------------------------\n",
        "\"53 fully correct MBTI types out of 100\"\n",
        "\n",
        "F1-score: 73.219%\n",
        "MBTI Type: EI\n",
        "\n",
        "F1-score: 77.578%\n",
        "MBTI Type: NS\n",
        "\n",
        "F1-score: 78.888%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 67.625%\n",
        "MBTI Type: PJ\n",
        "\n",
        "### XGB ------------------------------------------\n",
        "\"{j} fully correct MBTI types out of 100\"\n",
        "\n",
        "F1-score: 60.718%\n",
        "MBTI Type: EI\n",
        " \n",
        "F1-score: 60.75000000000001%\n",
        "MBTI Type: NS \n",
        "\n",
        "F1-score: 78.408%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 54.04600000000001%\n",
        "MBTI Type: PJ\n",
        "\n",
        "\n",
        "### ADA ------------------------------------------\n",
        "\"{j} fully correct MBTI types out of 100\"\n",
        "\n",
        "F1-score: 58.536%\n",
        "MBTI Type: IE\n",
        "\n",
        "F1-score: 58.318999999999996%\n",
        "MBTI Type: NS\n",
        "\n",
        "F1-score: 66.681%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 57.265%\n",
        "MBTI Type: JP\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
