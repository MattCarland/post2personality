{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nz1xaYf4cEjg"
      },
      "source": [
        "### Strategy:\n",
        "1. Adjust Doc Freqency for PreProc\n",
        "2. Preproc Data\n",
        "3. Build, param, train, and predict data\n",
        "4. Document results\n",
        "5. Repeat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7HZ1m4t7MWt5"
      },
      "outputs": [],
      "source": [
        "###### GLOBAL ###########\n",
        "\n",
        "INSTALL_NEEDED = False\n",
        "\n",
        "## Load CSV Datasets\n",
        "MAKE_DATA = False\n",
        "ROWS = 105000 # Limit 105000\n",
        "DF1, DF2, DF3 = False, True, False\n",
        "ALL_ROWS = False\n",
        "\n",
        "# Make CSV for ValData\n",
        "VAL_DATA = False\n",
        "\n",
        "# Build PreProccessed Datasets\n",
        "## PICK ONE FOR PREPROCESSING ##\n",
        "# If all False, will attempt to load our preproccessed data\n",
        "PREPROCESS = False # Use our Preproccessing\n",
        "BERT_PREPROCESS = False # Use BERT Preproceccessing\n",
        "BERT_LOAD = False # Load Preproccessed BERT Data\n",
        "\n",
        "# Set model types for session ('SGD', 'XGB', 'ADA')\n",
        "MODEL_TYPE = 'XGB'\n",
        "\n",
        "# Build Models\n",
        "NEW_MODELS = True\n",
        "\n",
        "# Search for Parameters\n",
        "PARAMETER_SEARCH = False\n",
        "OLD_PARAMS = False\n",
        "\n",
        "# Train Models\n",
        "TRAIN = True\n",
        "\n",
        "# Predict Models\n",
        "PREDICT_TEST = True\n",
        "FULL_PREDICT_TEST = False\n",
        "\n",
        "###### GLOBAL ###########"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GZHOFp9D-Lj",
        "outputId": "f7dc9a6d-f041-4559-b59b-e0b79f965ae3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: ipdb in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.13.13)\n",
            "Requirement already satisfied: seaborn in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.12.2)\n",
            "Requirement already satisfied: scipy==1.10.0 in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (1.10.0)\n",
            "Requirement already satisfied: scikit-learn==1.2.1 in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (1.2.1)\n",
            "Requirement already satisfied: nltk in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (3.8.1)\n",
            "Requirement already satisfied: textblob in /home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.17.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement string (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for string\u001b[0m\u001b[31m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46kuz5a8FLnq",
        "outputId": "9a79d74d-bc46-4fd6-f291-38cf8e477b99"
      },
      "outputs": [],
      "source": [
        "# pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-c9_nz0Yi0Jz"
      },
      "outputs": [],
      "source": [
        "\n",
        "if INSTALL_NEEDED == True:  \n",
        "  import nltk\n",
        "  nltk.download('punkt')\n",
        "  nltk.download('stopwords')\n",
        "  nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mq9Xvxoh_-vw",
        "outputId": "d4afbd27-56f1-4bc8-d6fe-842b71f491ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data already loaded\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "from data.data import Data as data_csv\n",
        "from scripts.Preprocessing_full import *\n",
        "from model.model import *\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "\n",
        "if MAKE_DATA == True:\n",
        "  data_raw = data_csv().get_all_data()\n",
        "  \n",
        "  \n",
        "\n",
        "  data_list = []\n",
        "\n",
        "  # 8670 ROWS INPUT #\n",
        "  if DF1:\n",
        "    df1 = data_raw['twitter_MBTI']\n",
        "    df1 = df1[['label', 'text']]\n",
        "    df1.rename(columns={'label': 'type'}, inplace=True)\n",
        "    if ALL_ROWS == False:\n",
        "      df1 = df1.sample(n = ROWS, ignore_index = True)\n",
        "    data_list.append(df1)\n",
        "\n",
        "\n",
        "  # 106062 ROWS INPUT #\n",
        "  if DF2:\n",
        "    df2 = data_raw['MBTI 500']\n",
        "    df2 = df2[['type', 'posts']]\n",
        "    df2.rename(columns={'posts': 'text'}, inplace=True)\n",
        "    df2 = df2.sample(frac=1).reset_index(drop=True)\n",
        "    if VAL_DATA:\n",
        "        dfval = df2.iloc[ROWS:]\n",
        "        dfval.to_csv('data/csv/valdata.csv')    \n",
        "        print(\"Val data created, path = data/csv/valdata.csv\")\n",
        "    if ALL_ROWS == False:\n",
        "      df2 = df2.iloc[:ROWS]\n",
        "    data_list.append(df2)\n",
        "\n",
        "\n",
        "  # 7811 ROWS INPUT #\n",
        "  if DF3:\n",
        "    df3 = data_raw['mbti_1']\n",
        "    df3.rename(columns={'posts': 'text'}, inplace=True)\n",
        "    if ALL_ROWS == False:\n",
        "      df3 = df3.sample(n = ROWS, ignore_index = True)\n",
        "    data_list.append(df3)\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "\n",
        "\n",
        "  ## Combine all data \n",
        "  data_combined = pd.concat(data_list, ignore_index=True)\n",
        "  print(f\"data_combined ready with shape: {data_combined.shape}\")\n",
        "\n",
        "else:\n",
        "  print(\"Data already loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--zajHjRCPc0",
        "outputId": "ba5b209e-ff25-4fc6-b7e4-08dc36a79147"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "df_list_pp_105000 has been loaded as df_list\n",
            "IE: (50306, 2380)\n",
            "SN: (18212, 2376)\n",
            "FT: (72990, 2351)\n",
            "JP: (87961, 2373)\n"
          ]
        }
      ],
      "source": [
        "from scripts.Preprocessing_full import training_preprocessing, training_oversampling, training_balancing, training_vectorize\n",
        "# from scripts.BERT_preprocessing import bert_training_preprocessing\n",
        "\n",
        "\n",
        "if PREPROCESS:\n",
        "  df_pp = training_preprocessing(data_combined)\n",
        "  df_pp_os = training_oversampling(df_pp)\n",
        "  df_pp_os_bal = training_balancing(df_pp_os)\n",
        "  df_list = training_vectorize(df_pp_os_bal)\n",
        "\n",
        "  df_list[0].dropna(inplace = True)\n",
        "  df_list[1].dropna(inplace = True)\n",
        "  df_list[2].dropna(inplace = True)\n",
        "  df_list[3].dropna(inplace = True)\n",
        "\n",
        "  with open(f'data/prepro/dflist_pp_{ROWS}.pkl', 'wb') as file:\n",
        "    pickle.dump(df_list, file)\n",
        "  \n",
        "  print(f\"df_list_pp_{ROWS} has been saved\")\n",
        "  print(f\"IE: {df_list[0].shape}\")\n",
        "  print(f\"SN: {df_list[1].shape}\")\n",
        "  print(f\"FT: {df_list[2].shape}\")\n",
        "  print(f\"JP: {df_list[3].shape}\")\n",
        "\n",
        "elif BERT_PREPROCESS:\n",
        "#   df_list = bert_training_preprocessing(data_combined)\n",
        "\n",
        "  df_list[0].dropna(inplace = True)\n",
        "  df_list[1].dropna(inplace = True)\n",
        "  df_list[2].dropna(inplace = True)\n",
        "  df_list[3].dropna(inplace = True)\n",
        "\n",
        "  with open(f'data/prepro/dflist_pp_BERT_{ROWS}.pkl', 'wb') as file:\n",
        "    pickle.dump(df_list, file)\n",
        "  \n",
        "  print(f\"df_list_pp_BERT_{ROWS} has been saved\")\n",
        "  \n",
        "  with open(f'data/prepro/dflist_pp_BERT_{ROWS}.pkl', 'rb') as file:\n",
        "        df_list = pickle.load(file)\n",
        "  print(f\"data/prepro/dflist_pp_BERT_{ROWS} has been loaded\")\n",
        "  print(f\"IE: {df_list[0].shape}\")\n",
        "  print(f\"SN: {df_list[1].shape}\")\n",
        "  print(f\"FT: {df_list[2].shape}\")\n",
        "  print(f\"JP: {df_list[3].shape}\")\n",
        "\n",
        "elif BERT_LOAD:\n",
        "  with open(f'data/prepro/dflist_pp_BERT_{ROWS}.pkl', 'rb') as file:\n",
        "    df_list = pickle.load(file)\n",
        "  print(f\"data/prepro/dflist_pp_BERT_{ROWS} has been loaded as df_list\")\n",
        "  print(f\"IE: {df_list[0].shape}\")\n",
        "  print(f\"SN: {df_list[1].shape}\")\n",
        "  print(f\"FT: {df_list[2].shape}\")\n",
        "  print(f\"JP: {df_list[3].shape}\")\n",
        "  \n",
        "else:\n",
        "  with open(f'data/prepro/dflist_pp_{ROWS}.pkl', 'rb') as file:\n",
        "    df_list = pickle.load(file)\n",
        "  print(f\"df_list_pp_{ROWS} has been loaded as df_list\")\n",
        "  print(f\"IE: {df_list[0].shape}\")\n",
        "  print(f\"SN: {df_list[1].shape}\")\n",
        "  print(f\"FT: {df_list[2].shape}\")\n",
        "  print(f\"JP: {df_list[3].shape}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XSjxhLpgJQsc"
      },
      "source": [
        "<!--  -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8_z6_NvOCR8K"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model_list is NEW\n"
          ]
        }
      ],
      "source": [
        "if NEW_MODELS:\n",
        "  model_list = initialize_models(new_models = True,\n",
        "                               params = None,\n",
        "                               model_type = MODEL_TYPE)\n",
        "  print(\"model_list is NEW\")\n",
        "else:\n",
        "  model_list = load_models_pkl()\n",
        "  print(\"model_list is OLD\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "w_LKOyI9CT_5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "no params applied to model_list\n"
          ]
        }
      ],
      "source": [
        "if PARAMETER_SEARCH:\n",
        "  param_list = grid_search_all_models(df_list, \n",
        "                          model_type=MODEL_TYPE, \n",
        "                          rows_for_search=1000)\n",
        "  with open(f'model/param_list_{MODEL_TYPE}.pkl', 'wb') as file:\n",
        "    pickle.dump(param_list, file)\n",
        "  \n",
        "  model_list = initialize_models(params = param_list,\n",
        "                               model_type=MODEL_TYPE)\n",
        "  print(\"model_list is optimized on new params\")\n",
        "  \n",
        "elif OLD_PARAMS:\n",
        "  with open(f'model/param_list_{MODEL_TYPE}.pkl', 'rb') as file:\n",
        "    param_list = pickle.load(file)\n",
        "\n",
        "  model_list = initialize_models(params = param_list,\n",
        "                               model_type=MODEL_TYPE) \n",
        "  \n",
        "  print(\"model_list is optimized on old params\")\n",
        "\n",
        "else:\n",
        "    print(\"no params applied to model_list\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-Z-yfDLeCajV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score: 73.801%\n",
            "Model: GradientBoostingClassifier(n_estimators=500)\n",
            "MBTI Type: IE\n",
            "========================================\n",
            "F1-score: 76.644%\n",
            "Model: GradientBoostingClassifier(n_estimators=500)\n",
            "MBTI Type: NS\n",
            "========================================\n",
            "F1-score: 83.914%\n",
            "Model: GradientBoostingClassifier(n_estimators=500)\n",
            "MBTI Type: TF\n",
            "========================================\n",
            "F1-score: 71.986%\n",
            "Model: GradientBoostingClassifier(n_estimators=500)\n",
            "MBTI Type: JP\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "if TRAIN:\n",
        "  history = train_model(df_list, model_list)\n",
        "else:\n",
        "  print(\"Not Training\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/aforbesj/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction = ENFP 0.6952175265761695\n",
            "Actual = INTJ\n",
            "Prediction = INTJ 0.7400170943745221\n",
            "Actual = INTP\n",
            "Prediction = INTJ 0.7664580939773898\n",
            "Actual = INTJ\n",
            "Prediction = INTP 0.6574588195372144\n",
            "Actual = ENFP\n",
            "Prediction = ENFP 0.8088982998644572\n",
            "Actual = ENTP\n",
            "Prediction = ESTP 0.7176750539134926\n",
            "Actual = ISTJ\n",
            "Prediction = INFJ 0.6473689080344409\n",
            "Actual = INTP\n",
            "Prediction = INTJ 0.7579992942674685\n",
            "Actual = INTJ\n",
            "Prediction = INTJ 0.651340672948082\n",
            "Actual = INTJ\n",
            "Prediction = ESFP 0.6007951729906054\n",
            "Actual = INFJ\n",
            "Prediction = INFJ 0.8320796245522502\n",
            "Actual = INFJ\n",
            "Prediction = ENTJ 0.676302412227994\n",
            "Actual = INTJ\n",
            "Prediction = INFP 0.7273434034187714\n",
            "Actual = INTP\n",
            "Prediction = ISFJ 0.7151003731299695\n",
            "Actual = INFP\n",
            "Prediction = INFJ 0.6966512427189673\n",
            "Actual = INFJ\n",
            "Prediction = INTJ 0.7327953919545027\n",
            "Actual = INTJ\n",
            "Prediction = INFP 0.6743971605402805\n",
            "Actual = INFP\n",
            "Prediction = INFP 0.6075371291126003\n",
            "Actual = INFP\n",
            "Prediction = INTP 0.7393619498469479\n",
            "Actual = INTJ\n",
            "Prediction = INFJ 0.8320796245522502\n",
            "Actual = INFJ\n",
            "Prediction = ESTJ 0.7542673247783835\n",
            "Actual = ENTJ\n",
            "Prediction = INFJ 0.7631790252076356\n",
            "Actual = INFP\n",
            "Prediction = INTJ 0.8149152822023282\n",
            "Actual = INTJ\n",
            "Prediction = ENTP 0.8157181969238227\n",
            "Actual = INTJ\n",
            "Prediction = INFJ 0.8320796245522502\n",
            "Actual = INFJ\n",
            "Prediction = ENTP 0.7392000447705971\n",
            "Actual = ENTP\n",
            "Prediction = INFJ 0.8054911285289158\n",
            "Actual = INFJ\n",
            "Prediction = INTP 0.7733971731121693\n",
            "Actual = INTP\n",
            "Prediction = ESTP 0.5932545250857397\n",
            "Actual = INTP\n",
            "Prediction = ESTP 0.780593727907987\n",
            "Actual = ENTP\n",
            "Prediction = ESTP 0.8838576185619568\n",
            "Actual = ESTP\n",
            "Prediction = ENFP 0.7376313578168368\n",
            "Actual = INTP\n",
            "Prediction = INFP 0.8657484166785125\n",
            "Actual = INFP\n",
            "Prediction = INTJ 0.7507191957281152\n",
            "Actual = INTP\n",
            "Prediction = ENTP 0.8157181969238227\n",
            "Actual = INTJ\n",
            "Prediction = ISFJ 0.6520286001212774\n",
            "Actual = INTP\n",
            "Prediction = ENTP 0.8157181969238227\n",
            "Actual = INTJ\n",
            "Prediction = ENTP 0.8466432638926014\n",
            "Actual = ENTP\n",
            "Prediction = ESFP 0.7462928554792827\n",
            "Actual = ISFP\n",
            "Prediction = ISTJ 0.6779804347013921\n",
            "Actual = INTJ\n",
            "Prediction = ENTP 0.8891652684081223\n",
            "Actual = ENTP\n",
            "Prediction = ENTP 0.7392000447705971\n",
            "Actual = ENTP\n",
            "Prediction = INTP 0.6540697442066432\n",
            "Actual = INTP\n",
            "Prediction = INFP 0.711952570500884\n",
            "Actual = ENFP\n",
            "Prediction = ISFJ 0.6520286001212774\n",
            "Actual = INTP\n",
            "Prediction = ENTP 0.7392000447705971\n",
            "Actual = ENTP\n",
            "Prediction = ENTP 0.6545235572630932\n",
            "Actual = INTP\n",
            "Prediction = ESTP 0.7023545210978889\n",
            "Actual = ENFP\n",
            "Prediction = INFP 0.7816625610098816\n",
            "Actual = INFP\n",
            "Prediction = ENFJ 0.5918881542423899\n",
            "Actual = INFJ\n",
            "Prediction = INFP 0.8657484166785125\n",
            "Actual = INFP\n",
            "Prediction = INFP 0.7273434034187714\n",
            "Actual = INTP\n",
            "Prediction = ESTJ 0.7542673247783835\n",
            "Actual = ENTJ\n",
            "Prediction = ENFJ 0.5918881542423899\n",
            "Actual = INFJ\n",
            "Prediction = INTJ 0.8340871498150225\n",
            "Actual = INTJ\n",
            "Prediction = INTJ 0.7177759061590179\n",
            "Actual = INTJ\n",
            "Prediction = INTP 0.7574666433538799\n",
            "Actual = INTP\n",
            "Prediction = INTP 0.6574588195372144\n",
            "Actual = ENFP\n",
            "Prediction = ESTP 0.6288298145977986\n",
            "Actual = ENTP\n",
            "Prediction = INFP 0.8657484166785125\n",
            "Actual = INFP\n",
            "Prediction = INFJ 0.7120208011508339\n",
            "Actual = ISFJ\n",
            "Prediction = ESFP 0.7169095949387077\n",
            "Actual = INFP\n",
            "Prediction = ENTP 0.6893223274457505\n",
            "Actual = INTP\n",
            "Prediction = ENTP 0.873595471531544\n",
            "Actual = ENTP\n",
            "Prediction = INFJ 0.8100731409967825\n",
            "Actual = INFJ\n",
            "Prediction = ENFJ 0.6656001345789748\n",
            "Actual = ENFJ\n",
            "Prediction = INTP 0.7733971731121693\n",
            "Actual = INTP\n",
            "Prediction = ISFJ 0.6295436099132172\n",
            "Actual = INTJ\n",
            "Prediction = ENFP 0.7376313578168368\n",
            "Actual = INTP\n",
            "Prediction = ENTP 0.7033735903644492\n",
            "Actual = INTP\n",
            "Prediction = INFJ 0.8054911285289158\n",
            "Actual = INFJ\n",
            "Prediction = ESTP 0.7176750539134926\n",
            "Actual = ISTJ\n",
            "Prediction = ENTJ 0.7503081747353655\n",
            "Actual = INTJ\n",
            "Prediction = ENTP 0.7758250056986661\n",
            "Actual = ENTP\n",
            "Prediction = INTJ 0.7380246651404134\n",
            "Actual = INTJ\n",
            "Prediction = ENFP 0.7376313578168368\n",
            "Actual = INTP\n",
            "Prediction = ESTP 0.6288298145977986\n",
            "Actual = ENTP\n",
            "Prediction = INTJ 0.6714509479257508\n",
            "Actual = ENFP\n",
            "Prediction = ENTP 0.7033735903644492\n",
            "Actual = INTP\n",
            "Prediction = INFJ 0.6790607594538398\n",
            "Actual = INFJ\n",
            "Prediction = ESTJ 0.7542673247783835\n",
            "Actual = ENTJ\n",
            "Prediction = ENFJ 0.6856964657049247\n",
            "Actual = INFP\n",
            "Prediction = INTJ 0.7579992942674685\n",
            "Actual = INTJ\n",
            "Prediction = INTJ 0.8340871498150225\n",
            "Actual = INTJ\n",
            "Prediction = ISFJ 0.6295436099132172\n",
            "Actual = INTJ\n",
            "Prediction = INFJ 0.8320796245522502\n",
            "Actual = INFJ\n",
            "Prediction = INTP 0.7393619498469479\n",
            "Actual = INTJ\n",
            "Prediction = ISFJ 0.6520286001212774\n",
            "Actual = INTP\n",
            "Prediction = INFJ 0.7330025740636357\n",
            "Actual = INFJ\n",
            "Prediction = ENFP 0.7376313578168368\n",
            "Actual = INTP\n",
            "Prediction = ENFP 0.6697598440247188\n",
            "Actual = INFP\n",
            "Prediction = ENFP 0.8088982998644572\n",
            "Actual = ENTP\n",
            "Prediction = ENTP 0.8247519634617043\n",
            "Actual = INTP\n",
            "Prediction = ESTP 0.7176750539134926\n",
            "Actual = ISTJ\n",
            "Prediction = ESTJ 0.905278559349852\n",
            "Actual = ESTJ\n",
            "Prediction = ENFP 0.734792859253723\n",
            "Actual = INFP\n",
            "Prediction = ESFP 0.7169095949387077\n",
            "Actual = INFP\n",
            "Prediction = ESTP 0.8838576185619568\n",
            "Actual = ESTP\n",
            "Prediction = ESFP 0.6007951729906054\n",
            "Actual = INFJ\n",
            "Prediction = ENFJ 0.6814051692683428\n",
            "Actual = ENFP\n",
            "Prediction = ESTJ 0.905278559349852\n",
            "Actual = ESTJ\n",
            "42 fully correct MBTI types out of 100\n"
          ]
        }
      ],
      "source": [
        "from scripts.Preprocessing_full import prediction_preprocessing, prediction_vectorize\n",
        "from scripts.BERT_preprocessing import bert_prediction_preprocessing\n",
        "\n",
        "\n",
        "if PREDICT_TEST:\n",
        "  j = 0\n",
        "  df = pd.read_csv('data/csv/valdata.csv')\n",
        "  for i in range(101):\n",
        "    df = df.sample(n = 100, ignore_index=True)\n",
        "    estimation = df['type'].tolist()[0]\n",
        "    df_pred = df.drop(columns=['Unnamed: 0', 'type'])\n",
        "    if BERT_LOAD or BERT_PREPROCESS:\n",
        "        df_pred_list = bert_prediction_preprocessing(df_pred)\n",
        "    else:\n",
        "        df_pred_pp = prediction_preprocessing(df_pred)\n",
        "        df_pred_list = prediction_vectorize(df_pred_pp)\n",
        "    pred = predict_model(texts = df_pred_list, verbose = False)\n",
        "    print(f\"Prediction = {pred['type_prediction']} {pred['type_score']}\")\n",
        "    print(f\"Actual = {estimation}\")\n",
        "    if pred['type_prediction'] == estimation:\n",
        "      j += 1\n",
        "  print(f\"{j} fully correct MBTI types out of {i}\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xfVFzbNNmo4j"
      },
      "source": [
        "# DF Comparison (n=7000)\n",
        "### DF1 ------------------------------------------\n",
        "F1-score: 52.669999999999995%\n",
        "MBTI Type: EI\n",
        "\n",
        "F1-score: 53.102000000000004%\n",
        "MBTI Type: NS\n",
        "\n",
        "F1-score: 49.124%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 57.786% \n",
        "MBTI Type: PJ\n",
        "\n",
        "### DF2 ------------------------------------------\n",
        "F1-score: 60.718%\n",
        "MBTI Type: EI\n",
        " \n",
        "F1-score: 60.75000000000001%\n",
        "MBTI Type: NS \n",
        "\n",
        "F1-score: 78.408%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 54.04600000000001%\n",
        "MBTI Type: PJ\n",
        "\n",
        "\n",
        "### DF 3 -------------------------------------\n",
        "\n",
        "\n",
        "F1-score: 58.536%\n",
        "MBTI Type: IE\n",
        "\n",
        "F1-score: 58.318999999999996%\n",
        "MBTI Type: NS\n",
        "\n",
        "F1-score: 66.681%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 57.265%\n",
        "MBTI Type: JP\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mI2m3eud5cQ4"
      },
      "source": [
        "# Tuned Model Comparison (n=ALLROWS) MinDoc = .02, MaxDoc = .8\n",
        "### SGD ------------------------------------------\n",
        "\"53 fully correct MBTI types out of 100\"\n",
        "\n",
        "F1-score: 73.219%\n",
        "MBTI Type: EI\n",
        "\n",
        "F1-score: 77.578%\n",
        "MBTI Type: NS\n",
        "\n",
        "F1-score: 78.888%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 67.625%\n",
        "MBTI Type: PJ\n",
        "\n",
        "### XGB ------------------------------------------\n",
        "\"{j} fully correct MBTI types out of 100\"\n",
        "\n",
        "F1-score: 60.718%\n",
        "MBTI Type: EI\n",
        " \n",
        "F1-score: 60.75000000000001%\n",
        "MBTI Type: NS \n",
        "\n",
        "F1-score: 78.408%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 54.04600000000001%\n",
        "MBTI Type: PJ\n",
        "\n",
        "\n",
        "### ADA ------------------------------------------\n",
        "\"{j} fully correct MBTI types out of 100\"\n",
        "\n",
        "F1-score: 58.536%\n",
        "MBTI Type: IE\n",
        "\n",
        "F1-score: 58.318999999999996%\n",
        "MBTI Type: NS\n",
        "\n",
        "F1-score: 66.681%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 57.265%\n",
        "MBTI Type: JP\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tuned Model Comparison (n=ALLROWS) MinDoc = .02, MaxDoc = .1\n",
        "### SGD ------------------------------------------\n",
        "3 fully correct MBTI types out of 100\n",
        "\n",
        "F1-score: 33.571%\n",
        "MBTI Type: EI\n",
        "\n",
        "F1-score: 52.43299999999999%\n",
        "MBTI Type: NS\n",
        "\n",
        "F1-score: 71.90100000000001%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 50.18%\n",
        "MBTI Type: PJ\n",
        "\n",
        "\n",
        "### ADA ------------------------------------------\n",
        "8 fully correct MBTI types out of 100\n",
        "\n",
        "F1-score: 62.705%\n",
        "MBTI Type: IE\n",
        "\n",
        "F1-score: 69.761%\n",
        "MBTI Type: NS\n",
        "\n",
        "F1-score: 64.129%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 59.803%\n",
        "MBTI Type: JP\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tuned Model Comparison (n=ALLROWS) MinDoc = .02, MaxDoc = .4\n",
        "### SGD ------------------------------------------\n",
        "\"0 fully correct MBTI types out of 100\"\n",
        "\n",
        "F1-score: 73.831%\n",
        "MBTI Type: EI\n",
        "\n",
        "F1-score: 77.83%\n",
        "MBTI Type: NS\n",
        "\n",
        "F1-score: 78.205%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 66.624%\n",
        "MBTI Type: PJ\n",
        "\n",
        "### XGB ------------------------------------------\n",
        "\"{j} fully correct MBTI types out of 100\"\n",
        "\n",
        "F1-score: 60.718%\n",
        "MBTI Type: EI\n",
        " \n",
        "F1-score: 60.75000000000001%\n",
        "MBTI Type: NS \n",
        "\n",
        "F1-score: 78.408%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 54.04600000000001%\n",
        "MBTI Type: PJ\n",
        "\n",
        "\n",
        "### ADA ------------------------------------------\n",
        "\"8 fully correct MBTI types out of 100\"\n",
        "\n",
        "F1-score: 74.789\n",
        "MBTI Type: IE\n",
        "\n",
        "F1-score: 78.479%\n",
        "MBTI Type: NS\n",
        "\n",
        "F1-score: 78.49199999999999%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 67.766%\n",
        "MBTI Type: JP\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tuned Model Comparison (n=ALLROWS) MinDoc = .02, MaxDoc = .9\n",
        "### SGD ------------------------------------------\n",
        "0 fully correct MBTI types out of 100\n",
        "\n",
        "F1-score: 65.09%\n",
        "MBTI Type: EI\n",
        "\n",
        "F1-score: 48.423%\n",
        "MBTI Type: NS\n",
        "\n",
        "F1-score: 40.599000000000004%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 33.452%\n",
        "MBTI Type: PJ\n",
        "\n",
        "\n",
        "### ADA ------------------------------------------\n",
        "14 fully correct MBTI types out of 100\n",
        "\n",
        "F1-score: 56.257999999999996%\n",
        "MBTI Type: IE\n",
        "\n",
        "F1-score: 70.999%\n",
        "MBTI Type: NS\n",
        "\n",
        "F1-score: 68.296%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 60.927%\n",
        "MBTI Type: JP\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tuned Model Comparison (n=ALLROWS) MinDoc = .02, MaxDoc = .7\n",
        "### SGD ------------------------------------------\n",
        "1 fully correct MBTI types out of 100\n",
        "\n",
        "F1-score: 52.112%\n",
        "MBTI Type: EI\n",
        "\n",
        "F1-score: 69.526%\n",
        "MBTI Type: NS\n",
        "\n",
        "F1-score: 59.90299999999999%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 33.452%\n",
        "MBTI Type: PJ\n",
        "\n",
        "\n",
        "### ADA ------------------------------------------\n",
        "2 fully correct MBTI types out of 100\n",
        "\n",
        "F1-score: 66.07600000000001%\n",
        "MBTI Type: IE\n",
        "\n",
        "F1-score: 65.571%\n",
        "MBTI Type: NS\n",
        "\n",
        "F1-score: 62.552%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 60.831999999999994%\n",
        "MBTI Type: JP\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tuned Model Comparison (n=5000) MinDoc = .02, MaxDoc = .7, DF2 Only\n",
        "### SGD ------------------------------------------\n",
        "## 11 sec\n",
        "13 fully correct MBTI types out of 100\n",
        "\n",
        "F1-score: 33.396%\n",
        "MBTI Type: EI\n",
        "\n",
        "F1-score: 34.605999999999995%\n",
        "MBTI Type: NS\n",
        "\n",
        "F1-score: 62.931000000000004%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 33.95%\n",
        "MBTI Type: PJ\n",
        "\n",
        "### XGB ------------------------------------------\n",
        "## 21 min\n",
        "37 fully correct MBTI types out of 100\n",
        "\n",
        "F1-score: 63.349999999999994%\n",
        "MBTI Type: EI\n",
        " \n",
        "F1-score: 62.55%\n",
        "MBTI Type: NS \n",
        "\n",
        "F1-score: 63.526%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 62.999%\n",
        "MBTI Type: PJ\n",
        "\n",
        "\n",
        "### ADA ------------------------------------------\n",
        "## 2 min\n",
        "19 fully correct MBTI types out of 100\n",
        "\n",
        "F1-score: 60.58%\n",
        "MBTI Type: IE\n",
        "\n",
        "F1-score: 61.394000000000005%\n",
        "MBTI Type: NS\n",
        "\n",
        "F1-score: 70.284%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 57.07%\n",
        "MBTI Type: JP\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tuned Model Comparison (n=105000) MinDoc = .02, MaxDoc = .7, DF2 Only, Val Data Set\n",
        "### SGD ------------------------------------------\n",
        "## 1 min\n",
        "39 fully correct MBTI types out of 100\n",
        "\n",
        "F1-score: 66.196%\n",
        "MBTI Type: EI\n",
        "\n",
        "F1-score: 61.043000000000006%\n",
        "MBTI Type: NS\n",
        "\n",
        "F1-score: 82.717%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 70.094%\n",
        "MBTI Type: PJ\n",
        "\n",
        "### XGB ------------------------------------------\n",
        "## 7 hrs 40 mins\n",
        "41 fully correct MBTI types out of 100\n",
        "\n",
        "F1-score: 74.167%\n",
        "MBTI Type: EI\n",
        " \n",
        "F1-score: 78.706%\n",
        "MBTI Type: NS \n",
        "\n",
        "F1-score: 83.699%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 71.437%\n",
        "MBTI Type: PJ\n",
        "\n",
        "\n",
        "### ADA ------------------------------------------\n",
        "## 43 min\n",
        "21 fully correct MBTI types out of 100\n",
        "\n",
        "F1-score: 68.35799999999999%\n",
        "MBTI Type: IE\n",
        "\n",
        "F1-score: 66.898%\n",
        "MBTI Type: NS\n",
        "\n",
        "F1-score: 74.72999999999999%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 54.647%\n",
        "MBTI Type: JP\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predicting and comparing DF1, DF2, and DF3 on best model (XGB 105k)\n",
        "\n",
        "### XGB ------------------------------------------\n",
        "## 7 hrs 40 mins\n",
        "\n",
        "### twitter_MBTI as Val Set (43min)\n",
        "\n",
        "445 fully correct MBTI types out of 7810\n",
        "\n",
        "5.69782% correct full types\n",
        "\n",
        "15423 MBTI letters correct out of 31244 total\n",
        "\n",
        "49.36308% correct individual types\n",
        "\n",
        "\n",
        "### MBTI 500 as Val Set (5min)\n",
        "\n",
        "449 fully correct MBTI types out of 1066\n",
        "\n",
        "42.12008% correct full types\n",
        "\n",
        "3412 MBTI letters correct out of 4268 total\n",
        "\n",
        "79.94377% correct individual types\n",
        "\n",
        "\n",
        "### mbti_1 as Val Set\n",
        "\n",
        "1574 fully correct MBTI types out of 8674\n",
        "\n",
        "18.14618% correct full types\n",
        "\n",
        "22519 MBTI letters correct out of 34700 total\n",
        "\n",
        "64.89625% correct individual types\n",
        "\n",
        "\n",
        "### Model Stats\n",
        "F1-score: 74.167%\n",
        "MBTI Type: EI\n",
        " \n",
        "F1-score: 78.706%\n",
        "MBTI Type: NS \n",
        "\n",
        "F1-score: 83.699%\n",
        "MBTI Type: TF\n",
        "\n",
        "F1-score: 71.437%\n",
        "MBTI Type: PJ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "if FULL_PREDICT_TEST:\n",
        "\n",
        "    # Iterables\n",
        "    j = 0\n",
        "    l = 0\n",
        "    n = 0\n",
        "\n",
        "    # Get Data\n",
        "    df = pd.read_csv('data/csv/twitter_MBTI.csv')\n",
        "    df= df[['label', 'text']]\n",
        "    df.rename(columns={'label': 'type'}, inplace=True)\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        df_shuf = df.sample(n = 1, ignore_index=True)\n",
        "        estimation = df_shuf['type'].tolist()[0].upper()\n",
        "        df_pred = df_shuf.drop(columns='type')\n",
        "\n",
        "        if BERT_LOAD or BERT_PREPROCESS:\n",
        "            df_pred_list = bert_prediction_preprocessing(df_pred)\n",
        "        else:\n",
        "            df_pred_pp = prediction_preprocessing(df_pred)\n",
        "            df_pred_list = prediction_vectorize(df_pred_pp)\n",
        "\n",
        "        \n",
        "        pred = predict_model(texts = df_pred_list, verbose = False)\n",
        "        print(f\"Prediction = {pred['type_prediction']} {pred['type_score']}\")\n",
        "        print(f\"Actual = {estimation}\")\n",
        "        if pred['type_prediction'] == estimation:\n",
        "            j += 1\n",
        "        if pred['type_prediction'][0] == estimation[0]:\n",
        "            l += 1\n",
        "        if pred['type_prediction'][1] == estimation[1]:\n",
        "            l += 1\n",
        "        if pred['type_prediction'][2] == estimation[2]:\n",
        "            l += 1\n",
        "        if pred['type_prediction'][3] == estimation[3]:\n",
        "            l += 1\n",
        "        n += 4\n",
        "    \n",
        "    print(\"---------------------------\")\n",
        "    print(f\"twitter_MBTI as Val Set\\n\")\n",
        "    print(f\"{j} fully correct MBTI types out of {i}\\n\")\n",
        "    print(f\"{round((100*(j/i)),5)}% correct full types\\n\")\n",
        "    print(f\"{l} MBTI letters correct out of {n} total\\n\")\n",
        "    print(f\"{round((100*(l/n)),5)}% correct individual types\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pIn2fmOYCg8s"
      },
      "outputs": [],
      "source": [
        "if FULL_PREDICT_TEST: \n",
        "    j = 0\n",
        "    l = 0\n",
        "    n = 0\n",
        "\n",
        "    df = pd.read_csv('data/csv/valdata.csv')\n",
        "    for i in range(len(df)):\n",
        "        df_shuf = df.sample(n = 1, ignore_index=True)\n",
        "        estimation = df_shuf['type'].tolist()[0]\n",
        "        df_pred = df_shuf.drop(columns=['Unnamed: 0', 'type'])\n",
        "\n",
        "        if BERT_LOAD or BERT_PREPROCESS:\n",
        "            df_pred_list = bert_prediction_preprocessing(df_pred)\n",
        "        else:\n",
        "            df_pred_pp = prediction_preprocessing(df_pred)\n",
        "            df_pred_list = prediction_vectorize(df_pred_pp)\n",
        "\n",
        "        \n",
        "        pred = predict_model(texts = df_pred_list, verbose = False)\n",
        "        print(f\"Prediction = {pred['type_prediction']} {pred['type_score']}\")\n",
        "        print(f\"Actual = {estimation}\")\n",
        "        if pred['type_prediction'] == estimation:\n",
        "            j += 1\n",
        "        if pred['type_prediction'][0] == estimation[0]:\n",
        "            l += 1\n",
        "        if pred['type_prediction'][1] == estimation[1]:\n",
        "            l += 1\n",
        "        if pred['type_prediction'][2] == estimation[2]:\n",
        "            l += 1\n",
        "        if pred['type_prediction'][3] == estimation[3]:\n",
        "            l += 1\n",
        "        n += 4\n",
        "        \n",
        "    \n",
        "    print(\"---------------------------\")\n",
        "    print(f\"MBTI 500 as Val Set\\n\")\n",
        "    print(f\"{j} fully correct MBTI types out of {i}\\n\")\n",
        "    print(f\"{round((100*(j/i)),5)}% correct full types\\n\")\n",
        "    print(f\"{l} MBTI letters correct out of {n} total\\n\")\n",
        "    print(f\"{round((100*(l/n)),5)}% correct individual types\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "if FULL_PREDICT_TEST:\n",
        "    # iterables\n",
        "    j = 0\n",
        "    l = 0\n",
        "    n = 0\n",
        "    # get data\n",
        "    df = pd.read_csv('data/csv/mbti_1.csv')\n",
        "    df.rename(columns={'posts': 'text'}, inplace=True)\n",
        "    for i in range(len(df)):\n",
        "        df_shuf = df.sample(n = 1, ignore_index=True)\n",
        "        estimation = df_shuf['type'].tolist()[0].upper()\n",
        "        df_pred = df_shuf.drop(columns='type')\n",
        "\n",
        "        if BERT_LOAD or BERT_PREPROCESS:\n",
        "            df_pred_list = bert_prediction_preprocessing(df_pred)\n",
        "        else:\n",
        "            df_pred_pp = prediction_preprocessing(df_pred)\n",
        "            df_pred_list = prediction_vectorize(df_pred_pp)\n",
        "\n",
        "        \n",
        "        pred = predict_model(texts = df_pred_list, verbose = False)\n",
        "        print(f\"Prediction = {pred['type_prediction']} {pred['type_score']}\")\n",
        "        print(f\"Actual = {estimation}\")\n",
        "        if pred['type_prediction'] == estimation:\n",
        "            j += 1\n",
        "        if pred['type_prediction'][0] == estimation[0]:\n",
        "            l += 1\n",
        "        if pred['type_prediction'][1] == estimation[1]:\n",
        "            l += 1\n",
        "        if pred['type_prediction'][2] == estimation[2]:\n",
        "            l += 1\n",
        "        if pred['type_prediction'][3] == estimation[3]:\n",
        "            l += 1\n",
        "        n += 4\n",
        "            \n",
        "    \n",
        "    print(\"---------------------------\")\n",
        "    print(f\"mbti_1 as Val Set\\n\")\n",
        "    print(f\"{j} fully correct MBTI types out of {i}\\n\")\n",
        "    print(f\"{round((100*(j/i)),5)}% correct full types\\n\")\n",
        "    print(f\"{l} MBTI letters correct out of {n} total\\n\")\n",
        "    print(f\"{round((100*(l/n)),5)}% correct individual types\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
