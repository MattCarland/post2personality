{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1200 entries, 0 to 1199\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   type    1200 non-null   object\n",
      " 1   text    1200 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 18.9+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1017/3695169631.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.rename(columns={'label': 'type'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "from data.data import Data\n",
    "\n",
    "ROWS = 400 # Limit 6000\n",
    "# PreProcess it ALL!!!!\n",
    "## SIKE NOT ENOUGH MEMORY\n",
    "# LIMIT TO 10K ROWS INPUT #\n",
    "\n",
    "data_raw = Data().get_all_data()\n",
    "\n",
    "\n",
    "# 8670 ROWS INPUT #\n",
    "df1 = data_raw['twitter_MBTI']\n",
    "df1 = df1[['label', 'text']]\n",
    "df1.rename(columns={'label': 'type'}, inplace=True)\n",
    "df1 = df1.sample(n = ROWS, ignore_index = True, random_state = 1)\n",
    "\n",
    "# 106062 ROWS INPUT #\n",
    "df2 = data_raw['MBTI 500']\n",
    "df2 = df2[['type', 'posts']]\n",
    "df2.rename(columns={'posts': 'text'}, inplace=True)\n",
    "df2 = df2.sample(n = ROWS, ignore_index = True, random_state = 1) # > 15000 combined, > 20000 df1 + df2\n",
    "\n",
    "## SPECIFCALLY CREATING DIV 0 ERROR, ASK ABOUT IT ##\n",
    "# 7811 ROWS INPUT #\n",
    "df3 = data_raw['mbti_1']\n",
    "df3.rename(columns={'posts': 'text'}, inplace=True)\n",
    "df3 = df3.sample(n = ROWS, ignore_index = True, random_state = 1)\n",
    "# ####################################################\n",
    "\n",
    "## Combined all data for PP if desired\n",
    "data_combined = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "data_combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset contains 122553 rows\n",
      "\n",
      "cleaned dataset contains 1200 rows and 8 columns\n",
      "E-I dataset contains 545 rows and 2379 columns\n",
      "S-N dataset contains 291 rows and 2556 columns\n",
      "F-T dataset contains 1219 rows and 2408 columns\n",
      "P-J dataset contains 956 rows and 2436 columns\n"
     ]
    }
   ],
   "source": [
    "from scripts.Preprocessing_full import training_preprocessing, training_oversampling, training_balancing, training_vectorize\n",
    "\n",
    "\n",
    "## PreProccessing Still does not have proper pkl storage -> Check your own file first\n",
    "\n",
    "df_pp = training_preprocessing(data_combined)\n",
    "df_pp_os = training_oversampling(df_pp)\n",
    "df_pp_os_bal = training_balancing(df_pp_os)\n",
    "df_list = training_vectorize(df_pp_os_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score:53.773\n",
      "Model Type: ie\n",
      "F1-score:57.208000000000006\n",
      "Model Type: ns\n",
      "F1-score:58.867999999999995\n",
      "Model Type: ft\n",
      "F1-score:43.131\n",
      "Model Type: pj\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([SGDClassifier(), SGDClassifier(), SGDClassifier(), SGDClassifier()],\n",
       " [{'e': {'precision': 0.6153846153846154,\n",
       "    'recall': 0.23529411764705882,\n",
       "    'f1-score': 0.3404255319148936,\n",
       "    'support': 68},\n",
       "   'i': {'precision': 0.6231884057971014,\n",
       "    'recall': 0.8958333333333334,\n",
       "    'f1-score': 0.735042735042735,\n",
       "    'support': 96},\n",
       "   'accuracy': 0.6219512195121951,\n",
       "   'macro avg': {'precision': 0.6192865105908585,\n",
       "    'recall': 0.5655637254901961,\n",
       "    'f1-score': 0.5377341334788143,\n",
       "    'support': 164},\n",
       "   'weighted avg': {'precision': 0.6199526878211926,\n",
       "    'recall': 0.6219512195121951,\n",
       "    'f1-score': 0.5714209678921666,\n",
       "    'support': 164},\n",
       "   'bal_acc': 0.6192865105908585},\n",
       "  {'n': {'precision': 0.7230769230769231,\n",
       "    'recall': 0.7833333333333333,\n",
       "    'f1-score': 0.752,\n",
       "    'support': 60},\n",
       "   's': {'precision': 0.43478260869565216,\n",
       "    'recall': 0.35714285714285715,\n",
       "    'f1-score': 0.39215686274509803,\n",
       "    'support': 28},\n",
       "   'accuracy': 0.6477272727272727,\n",
       "   'macro avg': {'precision': 0.5789297658862876,\n",
       "    'recall': 0.5702380952380952,\n",
       "    'f1-score': 0.572078431372549,\n",
       "    'support': 88},\n",
       "   'weighted avg': {'precision': 0.6313469139556096,\n",
       "    'recall': 0.6477272727272727,\n",
       "    'f1-score': 0.6375044563279857,\n",
       "    'support': 88},\n",
       "   'bal_acc': 0.5789297658862876},\n",
       "  {'f': {'precision': 0.5891089108910891,\n",
       "    'recall': 0.6397849462365591,\n",
       "    'f1-score': 0.6134020618556701,\n",
       "    'support': 186},\n",
       "   't': {'precision': 0.5914634146341463,\n",
       "    'recall': 0.5388888888888889,\n",
       "    'f1-score': 0.563953488372093,\n",
       "    'support': 180},\n",
       "   'accuracy': 0.5901639344262295,\n",
       "   'macro avg': {'precision': 0.5902861627626177,\n",
       "    'recall': 0.589336917562724,\n",
       "    'f1-score': 0.5886777751138816,\n",
       "    'support': 366},\n",
       "   'weighted avg': {'precision': 0.5902668635516091,\n",
       "    'recall': 0.5901639344262295,\n",
       "    'f1-score': 0.5890830912899765,\n",
       "    'support': 366},\n",
       "   'bal_acc': 0.5902861627626177},\n",
       "  {'j': {'precision': 0.3592233009708738,\n",
       "    'recall': 0.2890625,\n",
       "    'f1-score': 0.3203463203463203,\n",
       "    'support': 128},\n",
       "   'p': {'precision': 0.5054347826086957,\n",
       "    'recall': 0.5849056603773585,\n",
       "    'f1-score': 0.5422740524781341,\n",
       "    'support': 159},\n",
       "   'accuracy': 0.4529616724738676,\n",
       "   'macro avg': {'precision': 0.4323290417897847,\n",
       "    'recall': 0.43698408018867924,\n",
       "    'f1-score': 0.4313101864122272,\n",
       "    'support': 287},\n",
       "   'weighted avg': {'precision': 0.4402254806935695,\n",
       "    'recall': 0.4529616724738676,\n",
       "    'f1-score': 0.44329583048206384,\n",
       "    'support': 287},\n",
       "   'bal_acc': 0.4323290417897847}])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.model import *\n",
    "model = initialize_model()\n",
    "\n",
    "hist = train_model(df_list, model)\n",
    "\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>put honestly look bryan look like guy passion ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  put honestly look bryan look like guy passion ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ENTP #\n",
    "\n",
    "df = data_raw['MBTI 500']\n",
    "df = df[['type', 'posts']]\n",
    "df.rename(columns={'posts': 'text'}, inplace=True)\n",
    "df = df.sample(n = 10, ignore_index = True, random_state = 1)\n",
    "\n",
    "df_pred = df.iloc[:1].drop(columns =['type'])\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.Preprocessing_full import prediction_preprocessing, prediction_vectorize\n",
    "\n",
    "## Current Step for Work, error is lack of terms?\n",
    "\n",
    "df_pred_pp = prediction_preprocessing(df_pred)\n",
    "df_pred_list = prediction_vectorize(df_pred_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>type_to_token_ratio</th>\n",
       "      <th>aa</th>\n",
       "      <th>ab</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abortion</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abt</th>\n",
       "      <th>...</th>\n",
       "      <th>younger</th>\n",
       "      <th>youre</th>\n",
       "      <th>youtube</th>\n",
       "      <th>youu</th>\n",
       "      <th>youve</th>\n",
       "      <th>yr</th>\n",
       "      <th>yung</th>\n",
       "      <th>yup</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.339394</td>\n",
       "      <td>0.656504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 2378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_word_length  type_to_token_ratio   aa   ab  ability  able  abortion   \n",
       "0         5.339394             0.656504  0.0  0.0      0.0   0.0       0.0  \\\n",
       "\n",
       "   absolute  absolutely  abt  ...  younger  youre  youtube  youu  youve   yr   \n",
       "0       0.0         0.0  0.0  ...      0.0    0.0      0.0   0.0    0.0  0.0  \\\n",
       "\n",
       "   yung  yup  zero  zone  \n",
       "0   0.0  0.0   0.0   0.0  \n",
       "\n",
       "[1 rows x 2378 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- ada\n- aespa\n- alex\n- announce\n- april\n- ...\nFeature names seen at fit time, yet now missing:\n- abstract\n- accomplish\n- acknowledge\n- acquaintance\n- actively\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Making sure to run the 4 models with the 4 dataframes, again a pipeline makes more sense\u001b[39;00m\n\u001b[1;32m      2\u001b[0m  \n\u001b[1;32m      3\u001b[0m \u001b[39m# When predicting, the model needs to see the same features as the original fit\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# So with new text, how do we pass the new features? \u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# Would uploading a pickle file help?\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m predict_model([model,model,model,model], df_pred_list)\n",
      "File \u001b[0;32m~/code/MattCarland/post2personality/model/model.py:94\u001b[0m, in \u001b[0;36mpredict_model\u001b[0;34m(model_list, text)\u001b[0m\n\u001b[1;32m     92\u001b[0m MBTI_type \u001b[39m=\u001b[39m []\n\u001b[1;32m     93\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m model_list:\n\u001b[0;32m---> 94\u001b[0m     prediction \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(text[i])\n\u001b[1;32m     95\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTesting prediction = \u001b[39m\u001b[39m{\u001b[39;00mprediction\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     96\u001b[0m     MBTI_type\u001b[39m.\u001b[39mappend(prediction)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages/sklearn/linear_model/_base.py:419\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[39mPredict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    418\u001b[0m xp, _ \u001b[39m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 419\u001b[0m scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_function(X)\n\u001b[1;32m    420\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(scores\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    421\u001b[0m     indices \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(scores \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, \u001b[39mint\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages/sklearn/linear_model/_base.py:400\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    397\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    398\u001b[0m xp, _ \u001b[39m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 400\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    401\u001b[0m scores \u001b[39m=\u001b[39m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n\u001b[1;32m    402\u001b[0m \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39mreshape(scores, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39mif\u001b[39;00m scores\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages/sklearn/base.py:548\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_data\u001b[39m(\n\u001b[1;32m    484\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    485\u001b[0m     X\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno_validation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params,\n\u001b[1;32m    490\u001b[0m ):\n\u001b[1;32m    491\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \n\u001b[1;32m    493\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[39m        validated.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 548\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_feature_names(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    550\u001b[0m     \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tags()[\u001b[39m\"\u001b[39m\u001b[39mrequires_y\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    551\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    552\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m estimator \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    553\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequires y to be passed, but the target y is None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    554\u001b[0m         )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/post2personality/lib/python3.10/site-packages/sklearn/base.py:481\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m missing_names \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    477\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    478\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    479\u001b[0m     )\n\u001b[0;32m--> 481\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- ada\n- aespa\n- alex\n- announce\n- april\n- ...\nFeature names seen at fit time, yet now missing:\n- abstract\n- accomplish\n- acknowledge\n- acquaintance\n- actively\n- ...\n"
     ]
    }
   ],
   "source": [
    "# Making sure to run the 4 models with the 4 dataframes, again a pipeline makes more sense\n",
    " \n",
    "# When predicting, the model needs to see the same features as the original fit\n",
    "# So with new text, how do we pass the new features? \n",
    "# Would uploading a pickle file help?\n",
    " \n",
    "predict_model([model,model,model,model], df_pred_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "post2personality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
